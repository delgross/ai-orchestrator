# OLLAMA CONFIGURATION (Source of Truth)
# ==========================================
# This file governs the Ollama Service Settings and Model Options.

ollama:
  auto_adjust_context: true
  base_url: http://127.0.0.1:11434
  num_ctx: 8192 # Default fallback

  model_options:
    default:
      temperature: 0.7
      top_p: 0.9

    # THE BRAIN: Llama 3.3 70B
    "llama3.3:70b":
      num_ctx: 32768
      temperature: 0.7
      top_p: 0.9
      keep_alive: -1

    "qwen2.5:7b-instruct":
      num_ctx: 16384
      temperature: 0.5 # Lower temp for logic/routing
      top_p: 0.8
      keep_alive: -1
    
    # THE EYES: Vision
    "llama3.2-vision:latest":
      num_ctx: 8192
      keep_alive: -1

# System Settings
system:
  keep_alive: -1 # Models loaded forever
  
  # Toggles
  finalizer_enabled: true
  router_enabled: true
  fallback_enabled: true
