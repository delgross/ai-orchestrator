agent:
  circuit_breaker:
    threshold: 5
    timeout: 60.0
  fallback:
    enabled: true
    model: ollama:llama3.3:70b-instruct-q8_0
  fs_root: ~/ai/agent_fs_root
  host: 127.0.0.1
  limits:
    http_timeout: 300
    max_list_entries: 10000
    max_read_bytes: 100000000
    max_tool_steps: 50
  mcp:
    model: ollama:llama3.3:70b-instruct-q8_0
  model: ollama:llama3.3:70b-instruct-q8_0
  performance:
    alert_threshold_ms: 10000.0
    degradation_factor: 2.0
  persona_model_switching_enabled: true
  port: 5460
  retry:
    attempts: 3
    backoff_factor: 0.5
  summarization:
    max_result_chars: 200000
    model: ollama:llama3.3:70b-instruct-q8_0
    threshold_chars: 50000
  tasks:
    model: ollama:llama3.3:70b-instruct-q8_0
  tools:
    cache_enabled: true
    cache_ttl: 300
    command_timeout: 60
    command_workdir: ~/Sync/Antigravity/ai
    enable_command_execution: true
    streaming_enabled: false
agent_runner:
  periodic_tasks:
    time_update:
      enabled: true
      interval: 60.0
      local_model: ollama:mistral:latest
      output_file: time/current_time.txt
      priority: low
      prompt: 'Get the current date and time and write it to {output_file}.

        Include:

        - Current date and time

        - Timezone

        - Day of week

        - Day of year

        - Week number

        - Format it nicely.

        '
      type: file
    weather_update:
      enabled: true
      idle_only: false
      interval: 300.0
      local_model: ollama:mistral:latest
      mcp_server: weather
      output_file: weather/current_weather.txt
      priority: low
      prompt: 'Get the current weather using the weather MCP server tools and write
        it to {output_file}.

        Include:

        - Timestamp of when weather was fetched

        - Temperature (both Fahrenheit and Celsius if available)

        - Current conditions (sunny, cloudy, rain, etc.)

        - Humidity percentage

        - Wind speed and direction

        - Any relevant weather alerts

        Format it nicely and make it readable.

        '
      type: mcp_file
mcp_servers:
  exa:
    query_params:
      exaApiKey: c34af6d2-015f-4b20-8021-c6a77bbf0001
    requires_internet: true
    type: sse
    url: https://mcp.exa.ai/mcp
  fetch:
    args:
    - mcp-server-fetch
    command: uvx
    type: stdio
  filesystem:
    args:
    - -y
    - '@modelcontextprotocol/server-filesystem'
    - /Users/bee/Sync/Antigravity/ai
    - /Users/bee/Downloads
    command: npx
    type: stdio
  firecrawl-mcp:
    args:
    - -y
    - firecrawl-mcp
    command: npx
    env:
      FIRECRAWL_API_KEY: fc-ca465c22960b45ebbb246c8cbbae468d
    requires_internet: true
    type: stdio
  macos_automator:
    args:
    - -y
    - '@steipete/macos-automator-mcp@latest'
    command: npx
    env: {}
    type: stdio
  mcp-pandoc:
    args:
    - mcp-pandoc
    command: uvx
    type: stdio
  memory-search:
    args:
    - -y
    - '@modelcontextprotocol/server-memory-search'
    command: npx
    env:
      SEARCH_API_KEY: test_key_123
    requires_internet: true
    type: stdio
  ollama:
    args:
    - /Users/bee/Sync/Antigravity/ai/agent_runner/ollama_server.py
    command: /Users/bee/Sync/Antigravity/ai/agent_runner/.venv/bin/python
    env:
      OLLAMA_BASE: http://127.0.0.1:11434
    type: stdio
  perplexity:
    args:
    - -y
    - '@perplexity-ai/mcp-server'
    command: npx
    env:
      PERPLEXITY_API_KEY: REDACTED
    requires_internet: true
    type: stdio
  playwright:
    args:
    - '@playwright/mcp@latest'
    command: npx
    env: {}
    type: stdio
  project-memory:
    args:
    - /Users/bee/Sync/Antigravity/ai/agent_runner/memory_server.py
    command: /Users/bee/Sync/Antigravity/ai/agent_runner/.venv/bin/python
    env:
      EMBED_MODEL: ollama:mxbai-embed-large
      GATEWAY_BASE: http://127.0.0.1:5455
      SURREAL_DB: memory
      SURREAL_NS: orchestrator
      SURREAL_PASS: root
      SURREAL_URL: ws://127.0.0.1:8000/rpc
      SURREAL_USER: root
    type: stdio
  scrapezy:
    args:
    - '@scrapezy/mcp'
    - --api-key=REDACTED
    - --json
    command: npx
    env:
      SCRAPEZY_API_KEY: REDACTED
    requires_internet: true
    type: stdio
  system-control:
    args:
    - /Users/bee/Sync/Antigravity/ai/agent_runner/system_control_server.py
    command: /Users/bee/Sync/Antigravity/ai/.venv/bin/python
    env:
      AGENT_URL: http://127.0.0.1:5460
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      PYTHONPATH: /Users/bee/Sync/Antigravity/ai
      ROUTER_URL: http://127.0.0.1:5455
    type: stdio
  tavily-search:
    args:
    - -y
    - tavily-mcp@0.1.3
    command: npx
    env:
      TAVILY_API_KEY: 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
    requires_internet: true
    type: stdio
  thinking:
    args:
    - -y
    - '@modelcontextprotocol/server-sequential-thinking'
    command: npx
    type: stdio
  time:
    args:
    - mcp-server-time
    cmd:
    - uvx
    - mcp-server-time
    command: uvx
    type: stdio
  weather:
    args:
    - -y
    - '@iflow-mcp/weather-mcp'
    command: npx
    env: {}
    requires_internet: true
    type: stdio
model_intelligence:
  agent:mcp:
    preferred_for:
    - universal
    skills:
    - Full System Orchestration
    - Multi-Agent Coordination
    - Long-term Memory Access
    - Cross-tool Reasoning
    weaknesses:
    - Operational overhead
    - Recursive loop latency
  claude-3-5-sonnet:
    preferred_for:
    - architect
    - interface_designer
    skills:
    - Articulate Writing
    - Complex Coding
    - Visual Understanding
    - Nuanced Tone
    weaknesses:
    - Stricter refusal triggers
  gemini-1.5-pro:
    preferred_for:
    - researcher
    skills:
    - Massive 2M Context
    - Google Ecosystem Sync
    - Fast Retrieval
    weaknesses:
    - Prompt injection sensitivity
  grok-2:
    preferred_for:
    - researcher
    skills:
    - Real-time X Access
    - Unfiltered Truth
    - High Sarcasm Mode
    weaknesses:
    - Beta stability
  ollama:mistral:latest:
    preferred_for:
    - interface_designer
    - mechanic
    skills:
    - Fast Response
    - Clean Summarization
    - Instruction Following
    - Lightweight Operation
    weaknesses:
    - Logic depth
    - Choice paralysis with many tools
  ollama:qwq:latest:
    preferred_for:
    - knowledge_architect
    - researcher
    skills:
    - Deep Local Reasoning
    - Uncensored Logic
    - Privacy-safe Research
    - Long-form Thinking
    weaknesses:
    - High Local Latency
    - Verbosity
    - High RAM usage
  openai:gpt-4o:
    preferred_for:
    - automator
    - pollinator
    skills:
    - Omni-modal Intelligence
    - Perfect Tool Following
    - High Speed
    - Balanced Reasoning
    weaknesses:
    - Privacy (Cloud)
    - Static knowledge cutoff
  openai:gpt-4o-mini:
    preferred_for:
    - automator
    - pollinator
    skills:
    - Ultra-Fast
    - Cheap
    - Excellent for Automation
    - High Rate Limits
    weaknesses:
    - Creative Depth
    - Deep Reasoning
  ollama:llama3.3:70b-instruct-q8_0:
    preferred_for:
    - architect
    - mission_controller
    skills:
    - Super-Intelligence
    - Infinite Context Management
    - Master Architect
    - Autonomous Research
    - Multi-step Planning
    weaknesses:
    - Cloud-dependent
    - Highest token cost
    - Occasional safety-overkill
  openai:o1:
    preferred_for:
    - architect
    - knowledge_architect
    skills:
    - Ph.D. Level Reasoning
    - Advanced Mathematics
    - Deep Code Logic
    - Complex Debugging
    weaknesses:
    - High latency
    - Limited concurrency
    - No system prompt support
  openai:o3-mini:
    preferred_for:
    - architect
    - interface_designer
    skills:
    - Fast Reasoning
    - Cost-Efficient Logic
    - Coding Excellence
    weaknesses:
    - Smaller knowledge base than o1
personas:
  architect:
    mission: Expert in project structure, modular design, and high-level coding standards.
      Focus on scalability and system integrity.
    name: The Architect
    preferred_model: ollama:llama3.3:70b-instruct-q8_0
    tools:
    - list_dir
    - read_text
    - write_text
    - path_info
    - mcp__thinking__sequentialthinking
  automator:
    mission: Expert in browser control and OS-level automation. Handles complex UI
      scripting and headless navigation.
    name: The Automator
    preferred_model: openai:gpt-4o-mini
    tools:
    - mcp__playwright__browser_navigate
    - mcp__playwright__browser_click
    - mcp__macos_automator__execute_script
    - execute_command
  interface_designer:
    mission: Specialized in dashboard UX, frontend logic (HTML/JS), and the orchestrator's
      administrative API endpoints.
    name: The Interface Designer
    preferred_model: ollama:mistral:latest
    tools:
    - read_text
    - write_text
    - execute_command
  knowledge_architect:
    mission: Expert in graph database optimization and semantic memory curation. Ensures
      the Knowledge Graph is accurate and dense.
    name: The Knowledge Architect
    preferred_model: ollama:qwq:latest
    tools:
    - mcp__project_memory__query_facts
    - mcp__project_memory__store_fact
    - mcp__project_memory__delete_fact
    - mcp__project_memory__semantic_search
  mechanic:
    mission: Expert in system health, log analysis, and automated error recovery.
      Keeps the orchestrator services running perfectly.
    name: The System Mechanic
    preferred_model: ollama:mistral:latest
    tools:
    - execute_command
    - list_dir
    - read_text
    - mcp__project_memory__check_health
  mission_controller:
    mission: Strategic partner focused on project continuity, milestone tracking,
      and identifying operational patterns.
    name: The Mission Controller
    preferred_model: ollama:llama3.3:70b-instruct-q8_0
    tools:
    - mcp__project_memory__record_system_state
    - mcp__project_memory__query_facts
    - mcp__thinking__sequentialthinking
  pollinator:
    mission: Specialized in biological data, weather patterns, and cross-pollinating
      local sensor data with global research RAGs.
    name: The Pollinator
    preferred_model: openai:gpt-4o-mini
    tools:
    - mcp__firecrawl_mcp__firecrawl_scrape
    - mcp__scrapezy__extract_structured_data
    - http_request
  researcher:
    mission: Specialized in deep information retrieval, synthesis, and real-world
      fact-checking with proper citations.
    name: The Researcher
    preferred_model: ollama:qwq:latest
    tools:
    - mcp__exa__web_search_exa
    - mcp__tavily_search__tavily_search
    - mcp__perplexity__perplexity_research
    - http_request
providers:
  openai:
    api_key_env: OPENAI_API_KEY
    base_url: https://api.openai.com/v1
    type: openai_compat
router:
  agent_runner:
    limits:
      max_list_entries: 5000
      max_read_bytes: 50000000
      max_tool_steps: 20
    url: http://127.0.0.1:5460
  auth_token: 9sYBjBLjAHKG8g8ZzzsUeBOvtzgQFHmX7oIeygdpzic
  base_url: http://127.0.0.1:5455
  host: 127.0.0.1
  http_timeout: 300
  local_concurrency: 1
  max_body_bytes: 10000000
  max_concurrency: 20
  mcp_tool_access_enabled: true
  models_cache_ttl: 300
  ollama:
    auto_adjust_context: true
    base_url: http://127.0.0.1:11434
    model_options:
      default:
        temperature: 0.7
        top_p: 0.9
      qwen3:30b:
        min_p: 0.0
        temperature: 0.7
        top_k: 20
        top_p: 0.8
    num_ctx: 32768
    router:
      cache_ttl: 300.0
      enabled: true
      model: ollama:llama3.3:70b-instruct-q8_0
      timeout: 10.0
      tool_filtering:
        enabled: true
        max_tools_aggressive: 10
        max_tools_moderate: 20
        min_confidence: 0.8
        mode: moderate
  port: 5455
  preferred_models:
  - agent:mcp
  - ollama:qwq:latest
  - ollama:qwen3:30b
  - ollama:mistral:latest
  - openai:gpt-4o
  - openai:gpt-4o-mini
  - openai:o1
  - openai:o3-mini
  - ollama:llama3.3:70b-instruct-q8_0
  - claude-3-5-sonnet
  - claude-3-opus
  - gemini-1.5-pro
  - grok-2
  - perplexity:llama-3.1-sonar-large
  providers_yaml: ~/ai/providers.yaml
  rag:
    base_url: http://127.0.0.1:5555
    query_path: /query
  surrealdb:
    base_url: http://127.0.0.1:8000
    database: memory
    namespace: orchestrator
    pass: root
    user: root
system:
  dev_mode: true
  internet_check_interval: 60
  log_level: INFO
  persistence_dir: ~/ai/agent_data
  profile: M3_ULTRA
  python_io_encoding: utf-8
