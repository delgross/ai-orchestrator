system:
  profile: M3_ULTRA
  internet_check_interval: 60
  persistence_dir: ~/ai/agent_data
  log_level: INFO
  dev_mode: true
  python_io_encoding: utf-8
router:
  host: 127.0.0.1
  port: 5455
  base_url: http://127.0.0.1:5455
  auth_token: 9sYBjBLjAHKG8g8ZzzsUeBOvtzgQFHmX7oIeygdpzic
  max_concurrency: 20
  local_concurrency: 1
  http_timeout: 300
  models_cache_ttl: 300
  max_body_bytes: 10000000
  providers_yaml: ~/ai/providers.yaml
  preferred_models:
  - agent:mcp
  - ollama:qwq:latest
  - ollama:qwen3:30b
  - ollama:mistral:latest
  - openai:gpt-4o
  - openai:gpt-4o-mini
  - openai:o1
  - openai:o3-mini
  - openai:gpt-5.2
  - claude-3-5-sonnet
  - claude-3-opus
  - gemini-1.5-pro
  - grok-2
  - perplexity:llama-3.1-sonar-large
  ollama:
    base_url: http://127.0.0.1:11434
    num_ctx: 32768
    auto_adjust_context: true
    router:
      enabled: true
      model: ollama:qwen3:3b
      timeout: 5.0
      cache_ttl: 300.0
      tool_filtering:
        enabled: true
        mode: moderate
        min_confidence: 0.7
        max_tools_aggressive: 5
        max_tools_moderate: 15
    model_options:
      qwen3:30b:
        temperature: 0.7
        top_p: 0.8
        top_k: 20
        min_p: 0.0
      default:
        temperature: 0.7
        top_p: 0.9
  agent_runner:
    url: http://127.0.0.1:5460
    limits:
      max_read_bytes: 50000000
      max_list_entries: 5000
      max_tool_steps: 20
  surrealdb:
    base_url: http://127.0.0.1:8000
    user: root
    pass: root
    namespace: orchestrator
    database: memory
  rag:
    base_url: http://127.0.0.1:5555
    query_path: /query
  mcp_tool_access_enabled: true
model_intelligence:
  openai:gpt-5.2:
    skills:
    - Super-Intelligence
    - Infinite Context Management
    - Master Architect
    - Autonomous Research
    - Multi-step Planning
    weaknesses:
    - Cloud-dependent
    - Highest token cost
    - Occasional safety-overkill
    preferred_for:
    - architect
    - mission_controller
  openai:o1:
    skills:
    - Ph.D. Level Reasoning
    - Advanced Mathematics
    - Deep Code Logic
    - Complex Debugging
    weaknesses:
    - High latency
    - Limited concurrency
    - No system prompt support
    preferred_for:
    - architect
    - knowledge_architect
  openai:o3-mini:
    skills:
    - Fast Reasoning
    - Cost-Efficient Logic
    - Coding Excellence
    weaknesses:
    - Smaller knowledge base than o1
    preferred_for:
    - architect
    - interface_designer
  ollama:qwq:latest:
    skills:
    - Deep Local Reasoning
    - Uncensored Logic
    - Privacy-safe Research
    - Long-form Thinking
    weaknesses:
    - High Local Latency
    - Verbosity
    - High RAM usage
    preferred_for:
    - knowledge_architect
    - researcher
  ollama:mistral:latest:
    skills:
    - Fast Response
    - Clean Summarization
    - Instruction Following
    - Lightweight Operation
    weaknesses:
    - Logic depth
    - Choice paralysis with many tools
    preferred_for:
    - interface_designer
    - mechanic
  openai:gpt-4o:
    skills:
    - Omni-modal Intelligence
    - Perfect Tool Following
    - High Speed
    - Balanced Reasoning
    weaknesses:
    - Privacy (Cloud)
    - Static knowledge cutoff
    preferred_for:
    - automator
    - pollinator
  openai:gpt-4o-mini:
    skills:
    - Ultra-Fast
    - Cheap
    - Excellent for Automation
    - High Rate Limits
    weaknesses:
    - Creative Depth
    - Deep Reasoning
    preferred_for:
    - automator
    - pollinator
  claude-3-5-sonnet:
    skills:
    - Articulate Writing
    - Complex Coding
    - Visual Understanding
    - Nuanced Tone
    weaknesses:
    - Stricter refusal triggers
    preferred_for:
    - architect
    - interface_designer
  gemini-1.5-pro:
    skills:
    - Massive 2M Context
    - Google Ecosystem Sync
    - Fast Retrieval
    weaknesses:
    - Prompt injection sensitivity
    preferred_for:
    - researcher
  grok-2:
    skills:
    - Real-time X Access
    - Unfiltered Truth
    - High Sarcasm Mode
    weaknesses:
    - Beta stability
    preferred_for:
    - researcher
  agent:mcp:
    skills:
    - Full System Orchestration
    - Multi-Agent Coordination
    - Long-term Memory Access
    - Cross-tool Reasoning
    weaknesses:
    - Operational overhead
    - Recursive loop latency
    preferred_for:
    - universal
personas:
  architect:
    name: The Architect
    mission: Expert in project structure, modular design, and high-level coding standards.
      Focus on scalability and system integrity.
    tools:
    - list_dir
    - read_text
    - write_text
    - path_info
    - mcp__thinking__sequentialthinking
    preferred_model: openai:gpt-5.2
  researcher:
    name: The Researcher
    mission: Specialized in deep information retrieval, synthesis, and real-world
      fact-checking with proper citations.
    tools:
    - mcp__exa__web_search_exa
    - mcp__tavily_search__tavily_search
    - mcp__perplexity__perplexity_research
    - http_request
    preferred_model: ollama:qwq:latest
  automator:
    name: The Automator
    mission: Expert in browser control and OS-level automation. Handles complex UI
      scripting and headless navigation.
    tools:
    - mcp__playwright__browser_navigate
    - mcp__playwright__browser_click
    - mcp__macos_automator__execute_script
    - execute_command
    preferred_model: openai:gpt-4o-mini
  pollinator:
    name: The Pollinator
    mission: Specialized in biological data, weather patterns, and cross-pollinating
      local sensor data with global research RAGs.
    tools:
    - mcp__firecrawl_mcp__firecrawl_scrape
    - mcp__scrapezy__extract_structured_data
    - http_request
    preferred_model: openai:gpt-4o-mini
  mechanic:
    name: The System Mechanic
    mission: Expert in system health, log analysis, and automated error recovery.
      Keeps the orchestrator services running perfectly.
    tools:
    - execute_command
    - list_dir
    - read_text
    - mcp__project_memory__check_health
    preferred_model: ollama:mistral:latest
  knowledge_architect:
    name: The Knowledge Architect
    mission: Expert in graph database optimization and semantic memory curation. Ensures
      the Knowledge Graph is accurate and dense.
    tools:
    - mcp__project_memory__query_facts
    - mcp__project_memory__store_fact
    - mcp__project_memory__delete_fact
    - mcp__project_memory__semantic_search
    preferred_model: ollama:qwq:latest
  mission_controller:
    name: The Mission Controller
    mission: Strategic partner focused on project continuity, milestone tracking,
      and identifying operational patterns.
    tools:
    - mcp__project_memory__record_system_state
    - mcp__project_memory__query_facts
    - mcp__thinking__sequentialthinking
    preferred_model: openai:gpt-5.2
  interface_designer:
    name: The Interface Designer
    mission: Specialized in dashboard UX, frontend logic (HTML/JS), and the orchestrator's
      administrative API endpoints.
    tools:
    - read_text
    - write_text
    - execute_command
    preferred_model: ollama:mistral:latest
agent:
  host: 127.0.0.1
  port: 5460
  model: ollama:llama3.3:70b-instruct-q8_0
  persona_model_switching_enabled: false
  fs_root: ~/ai/agent_fs_root
  fallback:
    enabled: false
    model: openai:gpt-5.2
  summarization:
    model: ollama:llama3.3:70b-instruct-q8_0
    threshold_chars: 20000
    max_result_chars: 100000
  tasks:
    model: ollama:llama3.3:70b-instruct-q8_0
  mcp:
    model: ollama:llama3.3:70b-instruct-q8_0
  limits:
    max_tool_steps: 20
    max_read_bytes: 50000000
    max_list_entries: 5000
    http_timeout: 300
  tools:
    enable_command_execution: true
    command_timeout: 30
    command_workdir: ~/Sync/Antigravity/ai
    cache_enabled: true
    cache_ttl: 300
    streaming_enabled: false
  performance:
    alert_threshold_ms: 5000.0
    degradation_factor: 2.0
  circuit_breaker:
    threshold: 5
    timeout: 60.0
  retry:
    attempts: 2
    backoff_factor: 0.5
mcp_servers:
  fetch:
    type: stdio
    command: uvx
    args:
    - mcp-server-fetch
  filesystem:
    type: stdio
    command: npx
    args:
    - -y
    - "@modelcontextprotocol/server-filesystem"
    - /Users/bee/Sync/Antigravity/ai
  firecrawl-mcp:
    type: stdio
    command: npx
    args:
    - -y
    - firecrawl-mcp
    env:
      FIRECRAWL_API_KEY: fc-ca465c22960b45ebbb246c8cbbae468d
    requires_internet: true
  mcp-pandoc:
    type: stdio
    command: uvx
    args:
    - mcp-pandoc
  tavily-search:
    type: stdio
    command: npx
    args:
    - -y
    - tavily-mcp@0.1.3
    env:
      TAVILY_API_KEY: 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
    requires_internet: true
  exa:
    type: sse
    url: https://mcp.exa.ai/mcp
    query_params:
      exaApiKey: c34af6d2-015f-4b20-8021-c6a77bbf0001
    requires_internet: true
  scrapezy:
    type: stdio
    command: npx
    args:
    - '@scrapezy/mcp'
    - --api-key=REDACTED
    - --json
    env:
      SCRAPEZY_API_KEY: REDACTED
    requires_internet: true
  perplexity:
    type: stdio
    command: npx
    args:
    - -y
    - '@perplexity-ai/mcp-server'
    env:
      PERPLEXITY_API_KEY: REDACTED
    requires_internet: true
  thinking:
    type: stdio
    command: npx
    args:
    - -y
    - '@modelcontextprotocol/server-sequential-thinking'
  project-memory:
    type: stdio
    command: /Users/bee/Sync/Antigravity/ai/agent_runner/.venv/bin/python
    args:
    - /Users/bee/Sync/Antigravity/ai/agent_runner/memory_server.py
    env:
      SURREAL_URL: ws://127.0.0.1:8000/rpc
      SURREAL_USER: root
      SURREAL_PASS: root
      SURREAL_NS: orchestrator
      SURREAL_DB: memory
      EMBED_MODEL: ollama:mxbai-embed-large
      GATEWAY_BASE: http://127.0.0.1:5455
  ollama:
    type: stdio
    command: /Users/bee/Sync/Antigravity/ai/agent_runner/.venv/bin/python
    args:
    - /Users/bee/Sync/Antigravity/ai/agent_runner/ollama_server.py
    env:
      OLLAMA_BASE: http://127.0.0.1:11434
  playwright:
    type: stdio
    command: npx
    args:
    - '@playwright/mcp@latest'
    env: {}
  system-control:
    type: stdio
    command: /Users/bee/Sync/Antigravity/ai/.venv/bin/python
    args:
    - /Users/bee/Sync/Antigravity/ai/agent_runner/system_control_server.py
    env:
      ROUTER_URL: http://127.0.0.1:5455
      AGENT_URL: http://127.0.0.1:5460
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      PYTHONPATH: /Users/bee/Sync/Antigravity/ai
  macos_automator:
    type: stdio
    command: npx
    args:
    - -y
    - '@steipete/macos-automator-mcp@latest'
    env: {}
  weather:
    type: stdio
    command: npx
    args:
    - -y
    - '@iflow-mcp/weather-mcp'
    env: {}
    requires_internet: true
agent_runner:
  periodic_tasks:
    weather_update:
      type: mcp_file
      mcp_server: weather
      prompt: 'Get the current weather using the weather MCP server tools and write
        it to {output_file}.

        Include:

        - Timestamp of when weather was fetched

        - Temperature (both Fahrenheit and Celsius if available)

        - Current conditions (sunny, cloudy, rain, etc.)

        - Humidity percentage

        - Wind speed and direction

        - Any relevant weather alerts

        Format it nicely and make it readable.

        '
      output_file: weather/current_weather.txt
      local_model: ollama:mistral:latest
      interval: 300.0
      priority: low
      enabled: true
      idle_only: false
    time_update:
      type: file
      prompt: 'Get the current date and time and write it to {output_file}.

        Include:

        - Current date and time

        - Timezone

        - Day of week

        - Day of year

        - Week number

        - Format it nicely.

        '
      output_file: time/current_time.txt
      local_model: ollama:mistral:latest
      interval: 60.0
      priority: low
      enabled: true
providers:
  openai:
    type: openai_compat
    base_url: https://api.openai.com/v1
    api_key_env: OPENAI_API_KEY
