agent_runner:
  circuit_breaker:
    threshold: 5
    timeout: 300.0
  fallback:
    enabled: true
    model: ollama:llama3.3:70b-instruct-q8_0
  host: 127.0.0.1
  limits:
    http_timeout: 300
    max_list_entries: 10000
    max_read_bytes: 100000000
    max_tool_steps: 50
  model: xai:grok-2-1212
  periodic_tasks:
    time_update:
      enabled: true
      interval: 60.0
      local_model: ollama:llama3.1:latest
      output_file: time/current_time.txt
      priority: low
      prompt: 'Get the current date and time and write it to {output_file}.

        Include:

        - Current date and time

        - Timezone

        - Day of week

        - Day of year

        - Week number

        Format it nicely.

        '
      type: file
    weather_update:
      enabled: false
      idle_only: false
      interval: 300.0
      local_model: ollama:llama3.1:latest
      mcp_server: weather
      output_file: weather/current_weather.txt
      priority: low
      prompt: 'Get the current weather using the weather MCP server tools and write
        it to {output_file}.

        Include:

        - Timestamp of when weather was fetched

        - Temperature (F and C)

        - Current conditions (sunny, cloudy, rain, etc.)

        - Humidity percentage

        - Wind speed and direction

        - Any relevant weather alerts

        Format it nicely and make it readable.

        '
      type: mcp_file
  persona_model_switching_enabled: true
  port: 5460
  retry:
    attempts: 3
    backoff_factor: 0.5
  summarization:
    max_result_chars: 200000
    model: ollama:llama3.3:70b-instruct-q8_0
    threshold_chars: 50000
  tasks:
    model: ollama:llama3.3:70b-instruct-q8_0
  tools:
    cache_enabled: true
    cache_ttl: 300
    command_timeout: 60
    command_workdir: ~/Sync/Antigravity/ai
    enable_command_execution: true
    streaming_enabled: false
mcp_servers: {}

model_intelligence:
  agent:mcp:
    preferred_for:
    - universal
    skills:
    - Full System Orchestration
    - Multi-Agent Coordination
    - Long-term Memory Access
    weaknesses:
    - Operational overhead
  ollama:llama3.3:70b-instruct-q8_0:
    preferred_for:
    - architect
    - mission_controller
    skills:
    - Super-Intelligence
    - Infinite Context Management
  ollama:llama3.1:latest:
    preferred_for:
    - interface_designer
    - mechanic
    skills:
    - Fast Response
    - Clean Summarization
  openai:gpt-4o:
    preferred_for:
    - automator
    - pollinator
    skills:
    - Omni-modal Intelligence
    - Perfect Tool Following
  openai:o1:
    preferred_for:
    - architect
    - knowledge_architect
    skills:
    - Ph.D. Level Reasoning
    - Advanced Mathematics
    weaknesses:
    - High latency
    - No system prompt support
personas:
  architect:
    mission: Expert in project structure, modular design, and high-level coding standards.
    name: The Architect
    preferred_model: ollama:llama3.3:70b-instruct-q8_0
    tools:
    - list_dir
    - read_text
    - write_text
    - path_info
    - mcp__thinking__sequentialthinking
    - run_command
    - trigger_task
    - report_missing_tool
  automator:
    mission: Expert in browser control and OS-level automation.
    name: The Automator
    preferred_model: openai:gpt-4o-mini
    tools:
    - mcp__playwright__browser_navigate
    - mcp__playwright__browser_click
    - mcp__macos_automator__execute_script
    - run_command
    - trigger_task
    - report_missing_tool
  mechanic:
    mission: Expert in system health, log analysis, and automated error recovery.
    name: The System Mechanic
    preferred_model: ollama:llama3.1:latest
    tools:
    - run_command
    - list_dir
    - read_text
    - mcp__project_memory__check_health
    - trigger_task
    - report_missing_tool
providers:
  google:
    api_key_env: GEMINI_API_KEY
    base_url: https://generativelanguage.googleapis.com/v1beta/openai/
    type: openai_compat
  openai:
    api_key_env: OPENAI_API_KEY
    base_url: https://api.openai.com/v1
    type: openai_compat
  xai:
    api_key_env: GROK_API_KEY
    base_url: https://api.x.ai/v1
    type: openai_compat
router:
  agent_runner:
    limits:
      max_read_bytes: 50000000
      max_tool_steps: 20
    url: http://127.0.0.1:5460
  auth_token: 9sYBjBLjAHKG8g8ZzzsUeBOvtzgQFHmX7oIeygdpzic
  base_url: http://127.0.0.1:5455
  host: 127.0.0.1
  http_timeout: 300
  local_concurrency: 1
  max_body_bytes: 10000000
  max_concurrency: 20
  models_cache_ttl: 300
  ollama:
    auto_adjust_context: true
    base_url: http://127.0.0.1:11434
    model_options:
      default:
        temperature: 0.7
        top_p: 0.9
      qwen3:30b:
        min_p: 0.0
        temperature: 0.7
        top_k: 20
        top_p: 0.8
    num_ctx: 32768
    router:
      enabled: true
      model: ollama:llama3.3:70b-instruct-q8_0
      tool_filtering:
        enabled: true
        min_confidence: 0.8
        mode: moderate
  port: 5455
  preferred_models:
  - openai:gpt-5.1
  - openai:gpt-5.2
  - xai:grok-2-1212
  - ollama:llama3.3:70b-instruct-q8_0
  - ollama:llama3.1:latest
  - openai:gpt-4o-mini
  - agent:mcp
  - openai:o1
  - ollama:qwq:latest
  - ollama:mistral:latest
  - gemini-1.5-pro
  - gemini-exp-1206
  - grok-4-1-fast-reasoning
  - grok-3
  rag:
    base_url: http://127.0.0.1:5555
    query_path: /query
system:
  alert_file_path: ~/Desktop/Antigravity_Alerts.md
  dev_mode: true
  internet_check_interval: 60
  location:
    city: Newark
    country: United States
    enabled: true
    lat: 40.0732
    lon: -82.4017
    region: Ohio
    timezone: America/New_York
  log_level: INFO
  persistence_dir: ~/ai/agent_data
  profile: M3_ULTRA
